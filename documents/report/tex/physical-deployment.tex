\section{Objectives}
The main objective of this part of the project was to enable the running of octoDrone simulations on real hardware. While at first it may seem odd that we are attempting to move from a simulated programs to real ones when the overall goal of octoDrone is to allow for the simulation of real programs on virtual hardware. In a sense this a decision that logically follows the move from real to simulated - once I have built a program within the simulator framework and proved that it operates as I expect, it is infuriating to then have to implement this using a different set of frameworks on real hardware. It necessitates rewriting the same software in a way which effectively prohibits simulated benchmarks insomuch as there is no guarantee that simulated programs would exhibit the same performance characteristics as their real world counterparts given that they may be written on top of different libraries and possibly even in different languages. To this end it makes sense that one should want to run the same program in the simulator as in a real deployment.

There were a number of options that were explored in terms of the actual components that were used for our example deployment, similarly with the ways in which we adapted the simulator software to make the process as seamless as possible. The overall goal was to obtain a minimal working example, given that how well the hardware we could acquire would interact with what we had made was an unknown quantity. It is important to distinguish our efforts to make the simulator operate on real hardware units and the actual deployment we carried out. The former is a part of the product that is octoDrone, and was done to a high, professional standard. The latter was implemented using the components which were available to us through the department and, as such, does not represent what would be expected of a deployment carried out in industry. With that said, it is a testament to the flexibility of the simulator that it is possible to coerce it to run on distributed hardware components that it was never intended to support.

\section{Equipment and Feasibility}
The first decision to make with regards to the example deployment was to determine the type of hardware we would be targeting. There were two drones made available by the Department of Computer Science for our use - a pair of Parrot AR 2.0 Power Edition units.

\begin{aside}
\textbf{Parrot AR 2.0 specifications\cite{parrotspecs}}
\begin{itemize}
\item 1GHz 32 bit ARM Cortex A8 processor with 800MHz video DSP TMS320DMC64x
\item Linux kernel version 2.6.32
\item 1Gbit DDR2 RAM at 200MHz
\item Wi-Fi b,g,n
\item 3 axis gyroscope, accelerometer, and magnetometer
\item Ultrasound sensors for ground altitude measurement
\item 4 brushless inrunner motors. 14.5W 28,500 RPM
\item 30fps horizontal HD Camera (720p)
\item 60 fps vertical QVGA camera for ground speed measurement
\item Total weight 380g with outdoor hull, 420g with indoor hull
\end{itemize}
\end{aside}

\subsection{Micro-controllers}
The noteable thing missing from the above specifications is the ability to program the quadcopter with custom code. In a commercial or industrial deployment of this type, one would expect to use drones that are capable of being programmed themselves. Unfortunately these models are rather expensive, and as such we had to find a way to make the drones autonomous without being able to change the software running on them. The obvious solution was to use a micro-controller to pilot the drone because it would be easy to run our own custom software and communicate with the drone via its WiFi network. Below is a short summary of the investigation we did into the two major micro-controllers aimed at the consumer market (and thus within budget).

\subsubsection{Arduino}

\subsubsection{Raspberry Pi}

\subsection{Inter-node Communication}
In addition to communicating with the drone they were paired with, nodes would need to communicate with each other in order to pass messages and communicate with the base station. There were a number of options here which varied from true to life to more synthetic conditions.

\subsubsection{Radio}
In a real scenario, all communication done between nodes would be done using uni or bi-directional radio links. This allows for the use of software and protocols aimed at mobile sensor networks to facilitate the saving of power. It is obviously beneficial to create an environment which is as close as possible to real conditions, but we felt that this was less applicable for our example deployment. When we considered radio in the context of octoDrone, the abstraction of the physical and data link layers for communications meant that programs would not be able to tap into the extra power afforded by using it. In addition to this, many commercially available radio modules are designed to be used with the Arduino, which we had elected not to use.

\subsubsection{WiFi}
The second option we investigated was IEEE 802.11. The advantages over radio links were clear - it was easier to set up and use in in terms of program code, with many common protocols working automatically thanks to support and drivers for the linux kernel. In addition to this, there are many easily available USB adapters that work out of the box with the Raspberry Pi and Raspbian (a spin off of the Debian Linux distribution). This comes at the cost of the ability to make as many decisions at the lower OSI levels, but on balance this would make the process of developing and testing the deployment much easier. We concluded at this point that WiFi was preferred as a communication method over radio.

\subsubsection{Ethernet}
At this point the net was cast wider, in an attempt to see if there were any other solutions to the problem that were no immediately obvious. At this point we realised that the assumption that the micro-controllers would have to be mounted on the quadcopters themselves was a false one. Not only would having the Raspberry Pi units situated on the ground make flight more stable by reducing weight, it would also mean that we could use Ethernet to connect nodes together. This also sidestepped the issue we were encountering where the model A Raspberry Pis that the Department had given us only had two USB ports. Using two of these for WiFi adapters would have left no room for a keyboard. While not an insurmountable problem, it would have made debugging in particular more difficult than it needed to be. For the reasons above, as well as the aforementioned lack of necessity for accurate real world deployment conditions (due to the lack of budget) we chose Ethernet as the means of connectivity between nodes.

\subsection{Sensor Data}
We also came across the problem of how we would deal with nodes sensing the environment. This largely came down to the decision to install sensors on the quadcopters or to have this data simulated as it would be done in a simulated environment. 

\subsubsection{Installing Physical Sensors}
The best way of testing how a real life deployment would perform would be to get real life sensor data from mobile units as a program is running. There were, however, a number of problems with this approach - because it required a processing unit to be mounted on the quadcopter to read the sensor data, choosing it ruled out Ethernet as a communication option. Another problem was that real data values are harder to reason about in terms of software correctness. Especially for a trial deployment such as this one, not being able to repeat experiments (even on the same day) and expect the same results was a real problem. The final issue with this method was that the temperature sensors provided to us by the department came only with a datasheet. A large amount of time would have had to be spent in order to get the sensors soldered correctly and interfacing with the Pi. Even then, anecdotal experience with these devices has shown that they can be finicky and inconsistent, especially given that they were almost certainly not originally intended to work with a Raspberry Pi.

\subsubsection{Synthetic Data}
The alternative to the above was to use the same synthetic data which we had used in the simulated versions of our programs. This had the benefit of keeping some part of the experiment simple while we measured the effects of other variables on the performance of octoDrone (such as wind speed). As the project matures it will make sense to switch to the use of real data at some future juncture, but that is outside the scope of the project in its current state. What this decision did allow us to do was to test a number of edge cases on the real quadcopters which would have only become apparent otherwise after hundreds of hours of testing. This approach of fixing some aspects of the deployment whilst experimenting with others has undoubtedly saved many hours of testing and debugging over the past few months.

\section{Adapting the Simulator Code}
With the equipment selection locked in (Parrot AR 2, Raspberry Pi model A, Ethernet connectivity and no sensors), we set about adapting the simulator to run distributed across a number of hosts. A large amount of thought had been put into the design of the simulator from the beginning to make this possible, but actually making it a reality was a difficult task. Certain pieces of information could be safely used in a distributed application, such as the locations of individual nodes. Nodes cannot access the locations of other nodes in the simulation anyway, and there is no need to check positions for collisions as this can safely be delegated to physics.

Other properties generate problems when run as part of a distributed application - the environment iterates over the list of messageables when broadcasting messages. We therefore needed to find a way to disseminate packets without knowing the other nodes present in the network (supplying each node with a list of other nodes and their addresses would be missing the point by a country mile). Movement also becomes problematic when one realises that mobile units will often move at a given speed for a given amount of time, as opposed to the speed/direction instructions that programs use to make calls to Drone::move.

In order to attempt to solve these problems we first had to decide how the simulator could be run on multiple hosts. By far the simplest way to do this was to run individual ``simulations'' on each physical machine and have these communicate somehow. Users would use the same simulation structure as for conventional use (an environment with drone programs and communications modules), but each environment would contain only one messageable. This meant that each hardware unit could run an individual simulation, and that we could hook in to the functions exposed by the simulator API. As such, each time a a call was made to a function that required a call to hardware (such as sending messages), this could be intercepted and run on hardware without any change to the simulator API with the exception of instantiation, which necessarily required information on network interfaces. 

It was useful to visualise how the sharded environment would look - figure \ref{simnorm} shows the thread structure of a simulated octoDrone run, which can be compared to the distributed version in figure \ref{simdist}. Note that the extra threads present in the distributed version of the software hook into the functions exposed by the simulator (a call to Environment::broadcast actually ends up going to the Comm server thread to be broadcast. This meant that the difference between compiling a simulation and a deployment application is as simple as linking against a different library.

\begin{figure}
\centering
\begin{tikzpicture}[remember picture,
  simulator engine/.style={fill=black!10,rounded corners,inner sep=20pt,inner xsep=5pt},
  topology/.style={rounded corners,draw=blue!50,fill=blue!20,thick,inner sep=3pt},
  neuron/.style={fill=blue!10,draw=blue,rounded corners,inner sep=15pt,inner xsep=5pt,minimum width=3.5cm},
  synapse/.style={draw=red!75,fill=red!20,rounded corners,inner sep=5pt},
  empty synapse/.style={draw=blue!10,rounded corners,inner sep=5pt}
  ]
  \node[simulator engine] (simulatorEngine) {
    \begin{tikzpicture}
      \node[topology] (topology1) {
        \begin{tikzpicture}
          \node [neuron] (neuron1-1)  {
              \begin{tikzpicture}
                  \node [synapse,draw=blue] (synapse1-1-0) {Program Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-0] (synapse1-1-1) {Comm Mod Thread};
              \end{tikzpicture}
          };
          \node [neuron,draw=blue,right=0.2cm of neuron1-1] (neuron1-2) {
              \begin{tikzpicture}
                  \node [synapse,draw=blue] (synapse1-2-0) {Program Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-2-0] (synapse1-2-1) {Comm Mod Thread};
              \end{tikzpicture}
          };
          \node [neuron,draw=blue,right=0.2cm of neuron1-2] (neuron1-3) {
              \begin{tikzpicture}
                  \node [synapse,draw=blue] (synapse1-3-0) {Program Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-3-0] (synapse1-3-1) {Comm Mod Thread};
              \end{tikzpicture}
          };
          \node [synapse,draw=blue,below=0.2cm of neuron1-2,minimum width=12cm,minimum height=0.5cm] (synapse1-4) {
          };

          \node [black,below] at (neuron1-1.north)  {Drone A};
          \node [black,below] at (neuron1-2.north)  {Drone B};
          \node [black,below] at (neuron1-3.north)  {Base Station};
          \node [black,below] at (synapse1-4.north)	{Visualisation Thread};
        \end{tikzpicture}
      };

    \end{tikzpicture}
    };

    \node [black,below] at (simulatorEngine.north) {Simulation Environment};
\end{tikzpicture}
\caption{Thread diagram for octoDrone simulations}
\label{simnorm}
\end{figure}

\begin{figure}
\centering
\begin{tikzpicture}[remember picture,
  simulator engine/.style={fill=black!10,rounded corners,inner sep=20pt,inner xsep=5pt},
  topology/.style={rounded corners,draw=blue!50,fill=blue!20,thick,inner sep=3pt},
  neuron/.style={fill=blue!10,draw=blue,rounded corners,inner sep=15pt,inner xsep=5pt,minimum width=3cm},
  synapse/.style={draw=red!75,fill=red!20,rounded corners,inner sep=5pt},
  empty synapse/.style={draw=blue!10,rounded corners,inner sep=5pt}
  ]
  \node[simulator engine] (simulatorEngine) {
    \begin{tikzpicture}
      \node[topology] (topology1) {
        \begin{tikzpicture}
          \node [neuron] (neuron1-1)  {
              \begin{tikzpicture}
                  \node [synapse,draw=blue] (synapse1-1-0) {Program Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-0] (synapse1-1-1) {Comm Mod Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-1] (synapse1-1-2) {Comm Server Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-2] (synapse1-1-3) {Node Server Thread};
              \end{tikzpicture}
          };
          \node [black,below] at (neuron1-1.north)  {Drone A};
        \end{tikzpicture}
      };

    \end{tikzpicture}
    };

    \node [black,below] at (simulatorEngine.north) {Simulation Environment};
\end{tikzpicture}
\begin{tikzpicture}[remember picture,
  simulator engine/.style={fill=black!10,rounded corners,inner sep=20pt,inner xsep=5pt,},
  topology/.style={rounded corners,draw=blue!50,fill=blue!20,thick,inner sep=3pt},
  neuron/.style={fill=blue!10,draw=blue,rounded corners,inner sep=15pt,inner xsep=5pt,minimum width=3cm},
  synapse/.style={draw=red!75,fill=red!20,rounded corners,inner sep=5pt},
  empty synapse/.style={draw=blue!10,rounded corners,inner sep=5pt}
  ]
  \node[simulator engine] (simulatorEngine) {
    \begin{tikzpicture}
      \node[topology] (topology1) {
        \begin{tikzpicture}
          \node [neuron] (neuron1-1)  {
              \begin{tikzpicture}
                  \node [synapse,draw=blue] (synapse1-1-0) {Program Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-0] (synapse1-1-1) {Comm Mod Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-1] (synapse1-1-2) {Comm Server Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-2] (synapse1-1-3) {Node Server Thread};
              \end{tikzpicture}
          };
          \node [black,below] at (neuron1-1.north)  {Drone B};
        \end{tikzpicture}
      };

    \end{tikzpicture}
    };

    \node [black,below] at (simulatorEngine.north) {Simulation Environment};
\end{tikzpicture}
\begin{tikzpicture}[remember picture,
  simulator engine/.style={fill=black!10,rounded corners,inner sep=20pt,inner xsep=5pt},
  topology/.style={rounded corners,draw=blue!50,fill=blue!20,thick,inner sep=3pt},
  neuron/.style={fill=blue!10,draw=blue,rounded corners,inner sep=15pt,inner xsep=5pt,minimum width=3cm},
  synapse/.style={draw=red!75,fill=red!20,rounded corners,inner sep=5pt},
  empty synapse/.style={draw=blue!10,rounded corners,inner sep=5pt}
  ]
  \node[simulator engine] (simulatorEngine) {
    \begin{tikzpicture}
      \node[topology] (topology1) {
        \begin{tikzpicture}
          \node [neuron] (neuron1-1)  {
              \begin{tikzpicture}
                  \node [synapse,draw=blue] (synapse1-1-0) {Program Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-0] (synapse1-1-1) {Comm Mod Thread};
                  \node [synapse,draw=blue,below=0.1cm of synapse1-1-1] (synapse1-1-2) {Comm Server Thread};
				  \node [empty synapse,below=0.35cm of synapse1-1-2] (synapse1-1-e) {};
              \end{tikzpicture}
          };
          \node [black,below] at (neuron1-1.north)  {Base Station};
        \end{tikzpicture}
      };

    \end{tikzpicture}
    };

    \node [black,below] at (simulatorEngine.north) {Simulation Environment};
\end{tikzpicture}
\caption{Thread diagram for octoDrone deployment}
\label{simdist}
\end{figure}

\subsection{Sending and Receiving Messages}
Because nodes must communicate with each other over a network (in this case Ethernet), they must be able to actually send packets to each other - a connection must be established between them. This introduces a problem in as much as nodes cannot know the addresses of other nodes in the network (as determined earlier in this section) they must use multicast or broadcast. Broadcasting is effectively deprecated in modern networks, with IPv6 removing it entirely. Add to this the fact that some devices will refuse to let broadcast packets cross the device boundary, it became clear that multicast was the only viable choice. In terms of implementation, raw C sockets were chosen due to their simplicity and speed. It would have been possible to use a wrapper on top of these (such as Boost), but would not have alleviated a significant amount of work during development and would not have made the application cross platform unless the threading library used had been changed from the linux POSIX threads (pthreads) library.

Because the receiving of messages was driven by the sending of messages in the original simulator, these actions had to be decoupled for the distributed version. Because listening for an incoming connection is a blocking action it would require another thread to be run whilst the remainder of the application was executing. This thread would take a reference to the local messageable on instantiation that would later be used to deliver messages. Because the application would multicast packets, any outgoing messages would have to be sent to a multicast address that was known to all nodes (specified during the compilation of either the environment library or the simulation).

\subsection{Movement}
As there are no native C or C++ bindings (or indeed, any bindings) for the Parrot AR 2, making the quadcopters move involves using the node js package \textit{ardrone}. The \textit{ardrone} package handles connecting to a drone on the same network as the device it is run on (parrot drones use a default IP address, making them easy to find), as well as sending packets to the drone which it can understand. We created a javascript server application that could be run alongside the distributed simulator that would take commands and use the package to transmit them to the drone to be carried out. This server was passed messages by the environment through a UNIX socket in the filesystem of the host device.

As mentioned above, there was an issue with how movement would be translated from the {speed, distance} format for used by the simulator and the {speed, time} format used by the drones. The first attempt at solving this problem assumed that the application would have easy access to GPS coordinates from the paired drone, and used this to perform location checks in the same way as for simulated runs. It was later learned that there was only one GPS unit available for the two quadcopters obtained, and extracting information from it at runtime was non-trivial. The fallback plan developed involved 
\section{Results}
\section{Review Against Original Objectives}
